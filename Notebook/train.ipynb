{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:17:36.569890Z",
     "start_time": "2023-05-23T12:17:36.329065200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "%run ConV_VAE.ipynb\n",
    "%run loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:17:38.360805600Z",
     "start_time": "2023-05-23T12:17:38.345185400Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:17:38.641989700Z",
     "start_time": "2023-05-23T12:17:38.626369200Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_vae(train_loader, net, optimizer, device=device):\n",
    "    \"\"\"\n",
    "    Trains variational autoencoder network for one epoch in batches.\n",
    "    Args:\n",
    "        train_loader: Data loader for training set.\n",
    "        net: Neural network model.\n",
    "        optimizer: Optimizer (e.g. SGD).\n",
    "        device: whether the network runs on cpu or gpu\n",
    "    \"\"\"\n",
    "    avg_loss = 0\n",
    "\n",
    "    # iterate through batches\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        # convert the inputs to run on GPU if set\n",
    "        inputs = inputs.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = ((inputs - outputs) ** 2).sum() + net.encoder.kl\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # keep track of loss and accuracy\n",
    "        avg_loss += loss\n",
    "    return avg_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:17:51.190021200Z",
     "start_time": "2023-05-23T12:17:49.279584400Z"
    }
   },
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(160, 50)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "mnist_data = CustomImageDataset('../sign_mnist_train.csv', transform=transform)\n",
    "# mnist_data = datasets.MNIST('./data',\n",
    "#                             transform=transforms.ToTensor(),\n",
    "#                             download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it into a dataloader for easier handling in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:17:52.796573Z",
     "start_time": "2023-05-23T12:17:52.765315800Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist_loader = torch.utils.data.DataLoader(mnist_data, batch_size=128, shuffle=False)\n",
    "# 159.29443 48.70142\n",
    "# Create a writer to write to Tensorboard\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create instance of Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = VarAutoencoder(latent_dim, s_img, hdims).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:18:21.014846200Z",
     "start_time": "2023-05-23T12:18:19.962827600Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ConvVarAutoencoder().cuda()\n",
    "# Create loss function and optimizer\n",
    "criterion = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:18:23.653833500Z",
     "start_time": "2023-05-23T12:18:23.638250200Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the number of epochs to for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:18:48.049520100Z",
     "start_time": "2023-05-23T12:18:25.840695200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148234.1875 47978.7109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'results/0.png'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 13\u001B[0m\n\u001B[0;32m     11\u001B[0m sample \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mrandn(\u001B[38;5;241m64\u001B[39m, \u001B[38;5;241m2048\u001B[39m)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     12\u001B[0m sample \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mdecoder(sample)\u001B[38;5;241m.\u001B[39mcpu()\n\u001B[1;32m---> 13\u001B[0m \u001B[43msave_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43msample\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mview\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m28\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m           \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mresults/\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m.png\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\conda\\lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    112\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    114\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 115\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\conda\\lib\\site-packages\\torchvision\\utils.py:151\u001B[0m, in \u001B[0;36msave_image\u001B[1;34m(tensor, fp, format, **kwargs)\u001B[0m\n\u001B[0;32m    149\u001B[0m ndarr \u001B[38;5;241m=\u001B[39m grid\u001B[38;5;241m.\u001B[39mmul(\u001B[38;5;241m255\u001B[39m)\u001B[38;5;241m.\u001B[39madd_(\u001B[38;5;241m0.5\u001B[39m)\u001B[38;5;241m.\u001B[39mclamp_(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, torch\u001B[38;5;241m.\u001B[39muint8)\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    150\u001B[0m im \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(ndarr)\n\u001B[1;32m--> 151\u001B[0m \u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\conda\\lib\\site-packages\\PIL\\Image.py:2428\u001B[0m, in \u001B[0;36mImage.save\u001B[1;34m(self, fp, format, **params)\u001B[0m\n\u001B[0;32m   2426\u001B[0m         fp \u001B[38;5;241m=\u001B[39m builtins\u001B[38;5;241m.\u001B[39mopen(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr+b\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   2427\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2428\u001B[0m         fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mw+b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2430\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   2431\u001B[0m     save_handler(\u001B[38;5;28mself\u001B[39m, fp, filename)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'results/0.png'"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    # Train on data\n",
    "    train_loss = train_vae(mnist_loader, model, optimizer, device)\n",
    "    print(train_loss.item(), model.encoder.kl.item(), end='\\n')\n",
    "    # Write metrics to Tensorboard\n",
    "    writer.add_scalars(\"Loss\", {'Train': train_loss}, epoch)\n",
    "    if epoch % 10 == 0:\n",
    "        torch.save(model.state_dict(), \"model_good_50.pt\")\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(64, 2048).to(device)\n",
    "            sample = model.decoder(sample).cpu()\n",
    "            save_image(sample.view(64, 1, 28, 28),\n",
    "                       'results/' + str(epoch) + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
