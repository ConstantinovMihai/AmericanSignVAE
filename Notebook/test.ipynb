{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:53:09.249944Z",
     "start_time": "2023-05-23T12:53:09.218671200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:53:09.296808600Z",
     "start_time": "2023-05-23T12:53:09.249944Z"
    }
   },
   "outputs": [],
   "source": [
    "%run ConV_VAE.ipynb\n",
    "%run loader.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:53:09.296808600Z",
     "start_time": "2023-05-23T12:53:09.296808600Z"
    }
   },
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:53:09.312891200Z",
     "start_time": "2023-05-23T12:53:09.296808600Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(epoch, model, loader):\n",
    "    model.eval()\n",
    "    test_losses = []\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(loader):\n",
    "            #data = data.transpose(0,1)\n",
    "            inputs, labels = data\n",
    "            #print(inputs.shape)\n",
    "            #inputs = inputs.unsqueeze(dim=0)\n",
    "            #print(inputs.shape)\n",
    "            recon_batch = model(inputs)\n",
    "            test_loss = ((data - recon_batch) ** 2).sum() + model.encoder.kl\n",
    "            test_losses.append(test_loss)\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                        recon_batch.view(128, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                           '../results/reconstruction/' + str(epoch) + '.png', nrow=n)\n",
    "    #print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "    return np.mean(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:53:09.328452200Z",
     "start_time": "2023-05-23T12:53:09.312891200Z"
    }
   },
   "outputs": [],
   "source": [
    "# normalize = transforms.Normalize(160, 50)\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToTensor(),\n",
    "#     normalize\n",
    "# ])\n",
    "# mnist_data = CustomImageDataset('../Data/sign_mnist_test.csv', transform=transform)\n",
    "# # mnist_data = datasets.MNIST('./data',\n",
    "# #                             transform=transforms.ToTensor(),\n",
    "# #                             download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put it into a dataloader for easier handling in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:53:09.344457300Z",
     "start_time": "2023-05-23T12:53:09.328452200Z"
    }
   },
   "outputs": [],
   "source": [
    "# mnist_loader = torch.utils.data.DataLoader(mnist_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:53:09.360083300Z",
     "start_time": "2023-05-23T12:53:09.344457300Z"
    }
   },
   "outputs": [],
   "source": [
    "# mnist_loader = torch.utils.data.DataLoader(mnist_data, batch_size=128, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-23T12:53:09.379814100Z",
     "start_time": "2023-05-23T12:53:09.364106600Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = ConvVarAutoencoder().to(device)\n",
    "# model.load_state_dict(torch.load(\"model_good_50.pt\", map_location=device))\n",
    "# writer = SummaryWriter()\n",
    "# epochs = 5\n",
    "# for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "#     # Test\n",
    "#     test_loss = test(epoch, model, mnist_loader)\n",
    "#     print(test_loss)\n",
    "#     # Write metrics to Tensorboard\n",
    "#     #writer.add_scalars(\"Loss\", {'Train': test_loss}, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
